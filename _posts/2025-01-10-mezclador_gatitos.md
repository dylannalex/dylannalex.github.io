---
title: Mezclador de Gatitos - Una Divertida Aplicaci칩n de los Autoencoders Variacionales
date: 2025-01-10 10:00:00
categories: [游 Machine Learning]
math: true
tags: [spanish]
permalink: /mezclador_gatitos/
---

[![P치gina Web](https://img.shields.io/badge/P%C3%A1gina_Web-Mezclador%20de%20Gatitos-blue)](https://mezclador-gatitos.streamlit.app/)
[![GitHub](https://img.shields.io/badge/Repositorio-%20GitHub-blue)](https://github.com/dylannalex/mezclador_de_gatitos/blob/main/README.md)
[![Licencia del Proyecto](https://img.shields.io/github/license/dylannalex/mezclador_de_gatitos?color=blue)](https://github.com/dylannalex/mezclador_de_gatitos/blob/main/LICENSE)

![png](/assets/img/posts/2025-01-10-mezclador_gatitos/cats.jpg)


쮸lguna vez has so침ado con poder fusionar dos adorables gatitos en uno solo? 춰Pues ahora puedes hacerlo realidad con el **Mezclador de Gatitos**! Este proyecto utiliza autoencoders variacionales para crear combinaciones 칰nicas de rostros de gatos, permiti칠ndote explorar c칩mo se fusionan distintas caracter칤sticas visuales de estos peque침os felinos.

En este post, te contar칠 brevemente c칩mo se llev칩 a cabo el proyecto desde el punto de vista de data science. Empezamos con la introducci칩n de los autoencoders variacionales. Luego, exploramos el dataset de rostros de gatos para entender sus caracter칤sticas y c칩mo esas propiedades impactan en la generaci칩n de im치genes. Finalmente, desarrollamos el modelo VAE probando diferentes arquitecturas e hiperpar치metros para obtener el mejor desempe침o en cuanto a calidad de reconstrucci칩n e interpolaci칩n.

> 춰Explora el Mezclador de Gatitos y crea tus propias combinaciones de gatitos! 
[Visita la aplicaci칩n ahora](https://mezclador-gatitos.streamlit.app/) y si te gusta, 
no olvides darle una estrellita 游 en [GitHub](https://github.com/dylannalex/mezclador_de_gatitos) para apoyarlo.
{: .prompt-info }

## Introducci칩n a los VAEs

Un **Autoencoder Variacional (VAE)** es un modelo de red neuronal cuyo objetivo final es aprender
una representaci칩n comprimida de los datos originales, llamada **espacio latente**.
A diferencia de un autoencoder tradicional, que solo comprime y reconstruye los datos, el VAE aprende
a modelar la distribuci칩n subyacente de los datos, permitiendo no solo reconstruir im치genes existentes,
sino tambi칠n generar nuevas im치genes realistas a partir de combinaciones o interpolaciones en el espacio latente.

![png](/assets/img/posts/2025-01-10-mezclador_gatitos/vae_example.png)


El espacio latente es una representaci칩n de menor dimensi칩n donde se capturan las caracter칤sticas
esenciales de las im치genes, como la forma general del gato, los colores o los patrones de pelaje.
Una vez obtenidas las representaciones en el espacio latente de dos im치genes de gatos, es posible 
realizar interpolaciones entre ellas, generando im치genes intermedias que muestran una transici칩n 
visual suave y continua entre ambas. Esto permite explorar c칩mo se fusionar칤an diferentes 
caracter칤sticas de dos gatos en im치genes generadas artificialmente.

![png](/assets/img/posts/2025-01-10-mezclador_gatitos/interpolation_example.png)

## Exploraci칩n de Datos

Para abordar este proyecto, utilizamos el dataset [Cats Faces 64x64 (for generative models)](https://www.kaggle.com/datasets/spandan2/cats-faces-64x64-for-generative-models/data).Este conjunto de datos contiene im치genes de rostros de gatos en resoluci칩n $$64 \times 64$$ y formato RGB, lo que lo hace ideal para tareas de generaci칩n y s칤ntesis de im치genes al reducir la complejidad computacional sin sacrificar detalles relevantes. 

El dataset incluye un total de 15,747 im치genes, todas etiquetadas bajo una 칰nica clase, gatos. Aunque no cuenta con una documentaci칩n detallada, la calidad y uniformidad de las im치genes permiten centrarse exclusivamente en la generaci칩n de rostros de gatos, eliminando la variabilidad de m칰ltiples dominios presente en otros datasets m치s complejos.

![png](/assets/img/posts/2025-01-10-mezclador_gatitos/dataset_examples.png){: width="550" }

Se puede observar que el dataset es altamente adecuado para tareas de generaci칩n de im치genes, ya que presenta caracter칤sticas consistentes y de calidad. Las im치genes est치n correctamente recortadas, con un m칤nimo de fondo, lo que asegura que el rostro del gato ocupa la mayor parte de cada fotograf칤a. Esto reduce la complejidad asociada con variaciones en el entorno o en los elementos de fondo.

Adem치s, se existe una homogeneidad en las poses, ya que la mayor칤a de los rostros est치n orientados de frente y mantienen una posici칩n similar en todas las muestras. Esta uniformidad facilita que el modelo generativo enfoque su aprendizaje en las caracter칤sticas espec칤ficas de los rostros de gatos, incrementando as칤 la probabilidad de obtener resultados coherentes y detallados durante la s칤ntesis de nuevas im치genes.

## Desarrollo del Modelo

Se probaron distintas arquitecturas de modelos VAE y, sobre todo, se experiment칩 con diferentes hiperpar치metros. 
El c칩digo implementado para crear VAEs de manera sencilla se encuentra disponible en 
[GitHub](https://github.com/dylannalex/mezclador_de_gatitos?tab=readme-ov-file#-paquete-para-la-implementaci%C3%B3n-del-vae), 
donde se ofrece un paquete que permite construir modelos VAE especificando 칰nicamente la cantidad de canales de cada capa convolucional.

El entrenamiento de los modelos se llev칩 a cabo utilizando una funci칩n de p칠rdida denominada [BetaLoss](https://github.com/dylannalex/mezclador_de_gatitos/blob/main/dev/src/vae.py#L137), 
que combina dos componentes: la p칠rdida de reconstrucci칩n y la p칠rdida latente ponderada por un par치metro $$\beta$$. 
Esta funci칩n se define como:

$$
\mathcal{L}_{\text{BetaVAE}} = \mathcal{L}_{\text{rec}} + \beta \cdot \mathcal{L}_{\text{latent}}
$$

El par치metro $$\beta$$ controla el equilibrio entre la calidad de reconstrucci칩n y la regularizaci칩n del espacio latente.  
Un valor de $$\beta < 1$$ favorece una mejor reconstrucci칩n de las im치genes, mientras que un valor de $$\beta > 1$$  
prioriza la regularizaci칩n del espacio latente mediante una mayor penalizaci칩n de la divergencia KL.

### Modelos Implementados

Se probaron 6 versiones de VAE. Los modelos **v1**, **v2**, **v4**, **v5** y **v6** comparten la misma arquitectura, con 
la 칰nica diferencia en la funci칩n de p칠rdida **BetaLoss**. 

En el modelo **v1**, se utiliza la funci칩n de p칠rdida est치ndar de las VAE con un valor de $$\beta = 1$$. En el modelo 
**v2**, el valor de $$\beta$$ se incrementa al doble, es decir, $$\beta = 2$$. Por otro lado, en los modelos **v4**, 
**v5** y **v6**, el valor de $$\beta$$ se reduce progresivamente a $$\beta = 0.5$$, $$\beta = 0.05$$ y $$\beta = 0.005$$ 
respectivamente. En cuanto al modelo **v3**, se utiliz칩 una arquitectura m치s simple, con menos capas y par치metros.



![png](/assets/img/posts/2025-01-10-mezclador_gatitos/vae_architectures.png)


### Experimentos

Para seleccionar el mejor modelo, se analizaron algunas muestras de las im치genes generadas y se evalu칩 la calidad 
de las reconstrucciones (es decir, qu칠 tan borrosas o n칤tidas se ven las im치genes reconstruidas) y la calidad de las 
interpolaciones (es decir, qu칠 tan fluidas y realistas son las transiciones generadas entre dos im치genes distintas).


En cuanto a la reconstrucci칩n, en la imagen se muestran en las columnas los distintos modelos evaluados, mientras 
que las filas representan diferentes im치genes del dataset. La primera columna corresponde a la imagen original, y 
cada una de las siguientes columnas representa la reconstrucci칩n generada por cada modelo. Se observa que el modelo 
**VAEv6** es el que produce la mejor reconstrucci칩n.

![png](/assets/img/posts/2025-01-10-mezclador_gatitos/seleccion_de_modelo_por_reconstruccion.png){: width="750" }

En cuanto a la interpolaci칩n, en la imagen cada fila corresponde a un modelo distinto. La primera y 칰ltima columna 
muestran dos im치genes originales del dataset, mientras que las columnas intermedias representan las transiciones 
generadas entre ambas im치genes. Nuevamente, se observa que el modelo **VAEv6** genera las mejores interpolaciones.

![png](/assets/img/posts/2025-01-10-mezclador_gatitos/seleccion_de_modelo_por_interpolacion.png){: width="750" }

### Conclusiones obtenidas

A partir de los experimentos realizados, se observ칩 que un aumento en el valor de $$\beta$$, que implica una mayor regularizaci칩n del espacio latente, afecta negativamente la capacidad de reconstrucci칩n de las im치genes. Por esta raz칩n, se descartaron los modelos v1 y v2.  

En cambio, al reducir el valor de $$\beta$$, la capacidad de reconstrucci칩n mejor칩 significativamente, sin comprometer de manera importante las interpolaciones. Por este motivo, el modelo v6 ($$\beta = 0.005$$) fue seleccionado como el mejor, ya que ofrece la **mejor calidad de reconstrucci칩n sin perder la regularizaci칩n adecuada del espacio latente**.

En cuanto al modelo v3, que presenta una arquitectura m치s simple y con menos par치metros, esta simplicidad result칩 insuficiente para capturar la complejidad de las im치genes de rostros de gatos. Por lo tanto, se consider칩 inviable para su uso en este contexto.